# 課題レポート3：自然言語処理してみよう
- 全体の流れ
  - [NLTKの解説本](https://www.nltk.org/book/)の0章〜12章まで、計13個のHTMLファイルをダウンロードせよ。
  - BoWベースの特徴ベクトル（Level 1 もしくは Level 2）を生成せよ。
  - 共起行列ベースの特徴ベクトル（Level3）を生成せよ。
  - （ラベル付き文書に対して分類タスク（Level4）を実行せよ。）　＊課題レポート4として設定予定。
- Level 1: 文書ファイル毎に、Bag-of-Wordsで特徴ベクトルを生成せよ。
  - 補足
    - HTMLタグ等の除去はしなくても良い。（しても良い＠Option扱い）
    - ストップワードは、最低でも利用するライブラリで用意されているものを使うこと。拡張 or 独自実装する分には自由。
      - ライブラリ例
        - nltk.corpus.stopwords
        - sklearn.feature_extraction.text.CountVectorizer(stop_words)　＊引数で指定可能
    - レポートには下記内容を含めること。
      - (a) 13x13のマトリックス表記で文書間類似度（コサイン類似度）を記せ。表示有効桁は3桁とせよ。
      - (b) コード上工夫した箇所があるなら該当箇所だけを示し、解説せよ。ほぼコード例通りなら省略OK。
        - レポート上省略する場合でも、ソースコードは提出すること。
      - (c) 最も類似している2文書について、それらが類似していると判定された理由を検討し、述べよ。（単にコサイン類似度が大きいからではなく、何故大きいのかを検討してみよう）
- Level 2: BoWにTF-IDFで重み調整した特徴ベクトルを生成せよ。
  - レポートには下記内容を含めること。
    - (a) 〜 (c)：Level 1参照。
    - (d) Level 1, 2の(a)を比較し、順位が入れ替わっている箇所があるか探せ。もしあれば、それらの文書群について順序が入れ替わった理由を検討せよ。（単にコサイン類似度が変化したからではなく、変化に大きな影響を及ぼしたのがどこなのかを検討してみよう）
    - (e) (d)で入れ替わっている場合、この変化が好ましいか否か検討し、その理由とともに述べよ。
- Level 3: 単語の共起行列から特徴ベクトルを生成せよ。
  - レポートには下記内容を含めること。
    - (a) "natural", "language", "text", "count"に加え、もう1個以上の単語を自由に選べ。合計5個以上の単語についてマトリックス表記で単語間類似度（コサイン類似度）を記せ。表示有効桁は3桁とせよ。
    - (b) コード上工夫した箇所があるなら該当箇所だけを示し、解説せよ。ほぼコード例通りなら省略OK。
      - レポート上省略する場合でも、ソースコードは提出すること。
    - (c) 最も類似している2単語について、それらが類似していると判定された理由を検討し、述べよ。（単にコサイン類似度が大きいからではなく、何故大きいのかを検討してみよう）

---
以下はオプション例。

- オプション例
  - (a) 文書分類してみよう。
    - 教師あり学習用にラベル付けされたテキスト文書を準備し、BoW（もしくはBoW+TFIDF）, 共起行列に基づいた特徴ベクトルを用いて分類学習をしてみよう。
      - テキスト文書は任意で構わない。思いつかない場合には以下を利用しよう。なお、全文書を用いなくても良いが、最低限2カテゴリ選択し、カテゴリ毎に100文書以上サンプルを用意すること。
        - [sklearn.datasets.fetch_20newsgroups](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)
        - [Twitter日本語評判分析データセット](http://www.db.info.gifu-u.ac.jp/sentiment_analysis/)。ジャンル分類、極性（ネガティブ・ポジティブ）分類のラベルが付いている模様。データは別途ダウンロード必要で、Twitter API 制限のため2時間程度かかる模様。
        - [Sentiment Analysis in Twitter](https://www.cs.york.ac.uk/semeval-2013/task2/index.html)。極性分類。
        - [Opinion Mining, Sentiment Analysis, and Opinion Spam Detection](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#datasets)。レビュー記事にラベル付与されたデータがいくつかある模様。
      - Level 3の共起行列では単語ベクトルを生成しているだけである。これを用いて文書ベクトルを作るために、「文書中に現れた全単語の単語ベクトルを足し合わせ、総単語数で割る」ことで文書ベクトルとしよう。
      - 学習データとテストデータの割合、分類機（モデル）の選択等は自由で構わない。
      - レポートには下記内容を含めること。
        - 自身で設定したものは一通り記載しよう。
          - 例えば、特徴ベクトル生成時の設定等でLevel1〜3以外の処理。選択肢た分類器やハイパーパラメータの設定。学習のさせ方。評価のさせ方。
        - 評価結果。ラベル毎の精度を示そう。[混同行列（confusion matrix）](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)も記載すること。
        - レポート上省略する場合でも、ソースコードは提出すること。
  - (b) 相互情報量から特徴ベクトルを生成してみよう。
  - (c) 共起行列に基づいた特徴ベクトル、もしくは相互特徴量に基づいた特徴ベクトルをSVDにより次元削減してみよう。
  - (d) SVDによる次元削減時に2次元とせよ。気になる単語1つを選び、上位10件と下位10件を2次元空間にマッピングせよ。マッピング結果、どのように散らばっているか観察し、想定とどのぐらい似通っているか考察してみよう。
  - (e) 日本語文書について自然言語処理してみよう。
